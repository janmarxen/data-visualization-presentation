<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>t-SNE</title>
  <link rel="stylesheet" href="../style.css" />
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  <style>
    .why-section {
      background: #e8f5e9;
      border: 2px solid #4caf50;
      padding: 16px;
      border-radius: 8px;
      margin-top: 12px;
      font-size: 0.95rem;
      color: #1b5e20;
    }
    .why-title {
      font-weight: 700;
      color: #2e7d32;
      margin-bottom: 8px;
    }
    .parameter-note {
      background: #f3e5f5;
      padding: 12px 16px;
      border-radius: 6px;
      margin: 10px 0;
      font-size: 0.95rem;
    }
    .parameter-note strong {
      color: #6a1b9a;
    }
  </style>
</head>
<body>
  <div class="slide active">
    <h2>t-distributed Stochastic Neighbor Embedding (t-SNE)</h2>

    <div class="center-content">
      <div style="max-width: 950px; margin: 0 auto;">

        <!-- Step 1: Distance Computation -->
        <div class="tech-card" style="background: #f8f9fa; border: 2px solid #6f42c1;
             margin-bottom: 20px; padding: 20px;">
          <h3 style="color: #3c1361; margin-bottom: 12px;">1Ô∏è‚É£ Compute Pairwise Distances \(d_{ij}\) (here: shortest path)</h3>
        </div>

        <!-- Step 2: High-Dimensional Probabilities -->
        <div class="tech-card" style="background: #f8f9fa; border: 2px solid #17a2b8;
             margin-bottom: 20px; padding: 20px;">
          <h3 style="color: #0c5460; margin-bottom: 12px;">2Ô∏è‚É£ Measure Similarities in High Dimensions</h3>
          
          <p style="color: #333; font-size: 1rem; margin-bottom: 10px;">
            <strong>a)</strong> Convert distances \(d_{ij}\) into conditional probabilities \(p_{j|i}\) using a Gaussian distribution:
            \[
              p_{j|i} = \frac{\exp(-d_{ij}^2 / 2\sigma_i^2)}{\sum_{k \ne i} \exp(-d_{ik}^2 / 2\sigma_i^2)}
            \]
            where \(p_{j|i}\) is the probability that \(j\) is a neighbor of \(i\).
          </p>

          <p style="color: #333; font-size: 0.95rem; margin: 10px 0 0 0;">
            <strong>b)</strong> Symmetrize to get joint probabilities:
            \[
              p_{ij} = \frac{p_{i|j} + p_{j|i}}{2N}, \quad p_{ii} = 0
            \]
          </p>
          
          <div class="why-section">
            <div class="why-title">‚öôÔ∏è How to Choose \(\sigma_i\)?</div>
            Choose \(\sigma_i\) so that the perplexity \(\kappa_i = 2^{-\sum_{j} p_{j|i}\log_2 p_{j|i}}\) matches a target value. Perplexity measures the effective number of neighbors: dense regions need small \(\sigma_i\), sparse regions need large \(\sigma_i\).
          </div>
        </div>

        <!-- Step 3: Low-Dimensional Probabilities -->
        <div class="tech-card" style="background: #f8f9fa; border: 2px solid #28a745;
             margin-bottom: 20px; padding: 20px;">
          <h3 style="color: #155724; margin-bottom: 12px;">3Ô∏è‚É£ Measure Similarities in Low Dimensions</h3>
          
          <p style="color: #333; font-size: 1rem; margin-bottom: 10px;">
            Define \(q_{ij}\) in the 2D output space using a heavy-tailed Student's t-distribution:
            \[
              q_{ij} = \frac{(1 + \|y_i - y_j\|^2)^{-1}}
              {\sum_{k \ne l} (1 + \|y_k - y_l\|^2)^{-1}}, \quad q_{ii}=0
            \]
          </p>
          
          <div class="why-section">
            <div class="why-title">ü§î Why Student's t-Distribution?</div>
            Solves the <strong>crowding problem</strong>: high-dimensional space has more room than 2D. A Gaussian would squeeze distant points too close together, causing overlapping clusters. The heavy-tailed t-distribution preserves distances better.
          </div>
        </div>

        <!-- Step 4: Optimization -->
        <div class="tech-card" style="background: #f8f9fa; border: 2px solid #6c757d;
             padding: 20px;">
          <h3 style="color: #343a40; margin-bottom: 12px;">4Ô∏è‚É£ Make Them Match (Optimization)</h3>
          
          <p style="color: #333; font-size: 1rem; margin-bottom: 10px;">
            Minimize the Kullback-Leibler divergence between \(p_{ij}\) and \(q_{ij}\):
            \[
              C_{KL} = \sum_{i \ne j} p_{ij}\,\log \frac{p_{ij}}{q_{ij}}
            \]
          </p>
          
          <div class="why-section">
            <div class="why-title">üí° What Happens?</div>
            Moves 2D points so that \(q_{ij}\) matches \(p_{ij}\) (weighted by \(p_{ij}\)). When matched perfectly, \(\log(p_{ij}/q_{ij}) = 0\). Therefore, similar points pull together and dissimilar points push apart.
          </div>
        </div>

      </div>
    </div>
  </div>
</body>
</html>



